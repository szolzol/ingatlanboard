import asyncio
from playwright.async_api import async_playwright
import pandas as pd
import time
import random
from datetime import datetime
import re
from urllib.parse import urlparse, parse_qs, urlencode, urlunparse

class UrlBasedPropertyScraper:
    def __init__(self):
        """URL-alap√∫ ingatlan scraper"""
        self.playwright = None
        self.browser = None
        self.context = None
        self.page = None
        
    async def connect_to_existing_chrome(self):
        """Kapcsol√≥d√°s m√°r fut√≥ Chrome b√∂ng√©sz≈ëh√∂z"""
        try:
            print("üîó Kapcsol√≥d√°s Chrome b√∂ng√©sz≈ëh√∂z...")
            self.playwright = await async_playwright().start()
            self.browser = await self.playwright.chromium.connect_over_cdp("http://localhost:9222")
            print("‚úÖ Chrome kapcsolat l√©trehozva")
            return True
        except Exception as e:
            print(f"‚ùå Chrome kapcsol√≥d√°si hiba: {str(e)}")
            print("üí° Ellen≈ërizd, hogy fut-e a debug Chrome:")
            print("   chrome.exe --remote-debugging-port=9222 --user-data-dir=chrome_debug")
            return False
    
    async def get_active_tab(self):
        """Akt√≠v tab megkeres√©se vagy √∫j tab l√©trehoz√°sa"""
        try:
            contexts = self.browser.contexts
            if not contexts:
                self.context = await self.browser.new_context()
            else:
                self.context = contexts[0]
                
            pages = self.context.pages
            if not pages:
                self.page = await self.context.new_page()
            else:
                self.page = pages[0]
                
            return True
        except Exception as e:
            print(f"‚ùå Tab keres√©si hiba: {str(e)}")
            return False
    
    def get_search_url_with_limit(self):
        """Bek√©ri a felhaszn√°l√≥t√≥l a keres√©si URL-t √©s hozz√°adja a limit param√©tert"""
        print("üîó INGATLAN KERES√âSI URL MEGAD√ÅSA")
        print("="*50)
        print("üí° P√©lda URL-ek:")
        print("   https://ingatlan.com/szukites/elado+lakas+kobanyi-ujhegy")
        print("   https://ingatlan.com/szukites/elado+haz+budapest")
        print("   https://ingatlan.com/szukites/elado+lakas+xiii-kerulet")
        print("")
        
        while True:
            search_url = input("üìç Add meg a keres√©si URL-t: ").strip()
            
            if not search_url:
                print("‚ùå K√©rlek add meg az URL-t!")
                continue
                
            if not search_url.startswith("https://ingatlan.com"):
                print("‚ùå Csak ingatlan.com URL-eket t√°mogatunk!")
                continue
                
            # URL param√©terek kezel√©se
            parsed = urlparse(search_url)
            query_params = parse_qs(parsed.query)
            
            # Limit param√©ter hozz√°ad√°sa/fel√ºl√≠r√°sa
            query_params['limit'] = ['300']
            
            # URL √∫jra√©p√≠t√©se
            new_query = urlencode(query_params, doseq=True)
            enhanced_url = urlunparse((
                parsed.scheme, parsed.netloc, parsed.path,
                parsed.params, new_query, parsed.fragment
            ))
                
            print(f"‚úÖ Tov√°bbfejlesztett URL: {enhanced_url}")
            print(f"üéØ Maximum tal√°latok: 300 ingatlan")
            
            return enhanced_url

    async def human_like_navigation(self, url):
        """Emberszer≈± navig√°l√°s"""
        try:
            await self.page.goto(url, timeout=30000)
            await asyncio.sleep(random.uniform(2.0, 4.0))
            
            # V√©letlenszer≈± scroll
            if random.choice([True, False]):
                scroll_amount = random.randint(200, 800)
                await self.page.evaluate(f"window.scrollBy(0, {scroll_amount})")
                await asyncio.sleep(random.uniform(0.5, 1.5))
                await self.page.evaluate("window.scrollTo(0, 0)")
                
        except Exception as e:
            print(f"  ‚ö†Ô∏è Navig√°l√°si hiba: {e}")

    async def check_for_cloudflare_challenge(self):
        """Cloudflare challenge ellen≈ërz√©se"""
        try:
            cloudflare_indicators = [
                ".cf-browser-verification",
                ".cf-checking-browser", 
                ".cf-challenge-container",
                "#cf-challenge-stage"
            ]
            
            for selector in cloudflare_indicators:
                element = await self.page.query_selector(selector)
                if element and await element.is_visible():
                    return True
                    
            page_title = await self.page.title()
            if page_title and ("checking your browser" in page_title.lower() or 
                              "cloudflare" in page_title.lower()):
                return True
                
            return False
        except:
            return False

    async def scrape_property_list(self, search_url):
        """Ingatlan lista scraping az URL alapj√°n"""
        print(f"\nüè† INGATLAN LISTA SCRAPING")
        print(f"üîó URL: {search_url}")
        
        await self.human_like_navigation(search_url)
        
        # Cloudflare check
        if await self.check_for_cloudflare_challenge():
            print(f"üö® Cloudflare challenge √©szlelve!")
            print(f"üí° Menj a b√∂ng√©sz≈ëbe √©s old meg a challenge-t, majd nyomj ENTER-t")
            input("‚å®Ô∏è  Nyomj ENTER-t a folytat√°shoz...")
            await asyncio.sleep(2)
        
        # Tal√°latok sz√°m√°nak ellen≈ërz√©se
        try:
            result_count_selectors = [
                ".results-num",
                ".search-results-count", 
                "[data-testid='results-count']",
                ".found-results"
            ]
            
            total_results = 0
            for selector in result_count_selectors:
                element = await self.page.query_selector(selector)
                if element:
                    text = await element.inner_text()
                    # Sz√°mok kinyer√©se a sz√∂vegb≈ël
                    numbers = re.findall(r'\d+', text.replace(' ', '').replace('\xa0', ''))
                    if numbers:
                        total_results = int(numbers[-1])  # Utols√≥ sz√°m √°ltal√°ban a tal√°latok sz√°ma
                        break
            
            print(f"üìä Tal√°lt ingatlanok sz√°ma: {total_results}")
            
        except Exception as e:
            print(f"‚ö†Ô∏è Tal√°latok sz√°m√°nak meghat√°roz√°sa sikertelen: {e}")
            total_results = 0
        
        # Ingatlan linkek gy≈±jt√©se
        properties = []
        
        try:
            # Ingatlan k√°rtya selectorok
            property_card_selectors = [
                ".listing-card",
                ".property-card", 
                ".result-item",
                ".search-result-item",
                "a[href*='/ingatlan/']"
            ]
            
            property_elements = []
            for selector in property_card_selectors:
                elements = await self.page.query_selector_all(selector)
                if elements:
                    property_elements = elements
                    print(f"‚úÖ Tal√°latok: {len(elements)} elem ({selector})")
                    break
            
            if not property_elements:
                print("‚ùå Nem tal√°lhat√≥k ingatlan elemek")
                return []
            
            print(f"üîç Adatok kinyer√©se {len(property_elements)} ingatlanb√≥l...")
            
            for i, element in enumerate(property_elements, 1):
                try:
                    # Link kinyer√©se
                    link_element = element if element.tag_name.lower() == 'a' else await element.query_selector("a[href*='/ingatlan/']")
                    if not link_element:
                        continue
                        
                    href = await link_element.get_attribute("href")
                    if not href:
                        continue
                        
                    # Teljes URL l√©trehoz√°sa
                    if href.startswith('/'):
                        full_url = f"https://ingatlan.com{href}"
                    else:
                        full_url = href
                    
                    # Alapadatok kinyer√©se a list√°b√≥l
                    property_data = {
                        'id': i,
                        'link': full_url
                    }
                    
                    # C√≠m
                    try:
                        title_selectors = [".listing-title", ".property-title", "h3", "h4", ".title"]
                        for sel in title_selectors:
                            title_elem = await element.query_selector(sel)
                            if title_elem:
                                property_data['cim'] = await title_elem.inner_text()
                                break
                        else:
                            property_data['cim'] = ""
                    except:
                        property_data['cim'] = ""
                    
                    # √År
                    try:
                        price_selectors = [".price", ".listing-price", ".property-price", "[data-testid='price']"]
                        for sel in price_selectors:
                            price_elem = await element.query_selector(sel)
                            if price_elem:
                                property_data['teljes_ar'] = await price_elem.inner_text()
                                break
                        else:
                            property_data['teljes_ar'] = ""
                    except:
                        property_data['teljes_ar'] = ""
                    
                    # Ter√ºlet √©s szobasz√°m
                    try:
                        details_selectors = [".property-details", ".listing-details", ".details", ".params"]
                        details_text = ""
                        for sel in details_selectors:
                            details_elem = await element.query_selector(sel)
                            if details_elem:
                                details_text = await details_elem.inner_text()
                                break
                        
                        # Ter√ºlet kinyer√©se (pl. "65 m¬≤")
                        area_match = re.search(r'(\d+)\s*m¬≤', details_text)
                        property_data['terulet'] = f"{area_match.group(1)} m¬≤" if area_match else ""
                        
                        # Szobasz√°m (pl. "3 szoba")
                        room_match = re.search(r'(\d+)\s*szoba', details_text)
                        property_data['szobak'] = room_match.group(1) if room_match else ""
                        
                        # Nm √°r sz√°m√≠t√°sa ha van ter√ºlet √©s √°r
                        if property_data['teljes_ar'] and property_data['terulet']:
                            try:
                                price_numbers = re.findall(r'[\d,]+', property_data['teljes_ar'].replace(' ', ''))
                                area_numbers = re.findall(r'\d+', property_data['terulet'])
                                
                                if price_numbers and area_numbers:
                                    price_value = float(price_numbers[0].replace(',', '.'))
                                    area_value = int(area_numbers[0])
                                    
                                    if 'milli√≥' in property_data['teljes_ar'].lower():
                                        price_value *= 1000000
                                    elif 'ezer' in property_data['teljes_ar'].lower():
                                        price_value *= 1000
                                    
                                    if area_value > 0:
                                        nm_price = int(price_value / area_value)
                                        property_data['nm_ar'] = f"{nm_price:,} Ft/m¬≤".replace(',', ' ')
                                    else:
                                        property_data['nm_ar'] = ""
                                else:
                                    property_data['nm_ar'] = ""
                            except:
                                property_data['nm_ar'] = ""
                        else:
                            property_data['nm_ar'] = ""
                            
                    except:
                        property_data['terulet'] = ""
                        property_data['szobak'] = ""
                        property_data['nm_ar'] = ""
                    
                    properties.append(property_data)
                    
                    if i % 10 == 0:
                        print(f"  üìã Feldolgozva: {i}/{len(property_elements)}")
                        
                except Exception as e:
                    print(f"  ‚ö†Ô∏è {i}. elem feldolgoz√°si hiba: {e}")
                    continue
            
            print(f"‚úÖ Lista scraping befejezve: {len(properties)} ingatlan")
            return properties
            
        except Exception as e:
            print(f"‚ùå Lista scraping hiba: {e}")
            return []

    def save_properties_csv(self, properties, search_url):
        """Ingatlan lista ment√©se CSV-be"""
        if not properties:
            print("‚ùå Nincsenek mentend≈ë adatok")
            return None
            
        try:
            # F√°jln√©v gener√°l√°sa az URL alapj√°n
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            
            # URL-b≈ël keres√©si ter√ºlet kinyer√©se
            url_parts = search_url.split('/')
            search_term = url_parts[-1] if url_parts else "keres√©s"
            search_term = re.sub(r'[^\w\-_]', '_', search_term)[:30]  # Biztons√°gos f√°jln√©v
            
            filename = f"ingatlan_lista_{search_term}_{timestamp}.csv"
            
            df = pd.DataFrame(properties)
            
            # Oszlopok sorrendje
            columns = ['id', 'cim', 'teljes_ar', 'terulet', 'nm_ar', 'szobak', 'link']
            available_columns = [col for col in columns if col in df.columns]
            df = df[available_columns]
            
            df.to_csv(filename, index=False, encoding='utf-8-sig')
            
            print(f"\nüíæ Lista mentve: {filename}")
            print(f"üìä √ñsszesen {len(df)} ingatlan, {len(df.columns)} oszlop")
            
            return filename
            
        except Exception as e:
            print(f"‚ùå CSV ment√©si hiba: {e}")
            return None

    async def close(self):
        """Kapcsolat bez√°r√°sa"""
        try:
            if self.playwright:
                await self.playwright.stop()
        except:
            pass

async def main():
    """F≈ëf√ºggv√©ny URL-alap√∫ scraping-hez"""
    print("üè† URL-ALAP√ö INGATLAN SCRAPER")
    print("="*60)
    
    scraper = UrlBasedPropertyScraper()
    
    try:
        # URL bek√©r√©se
        search_url = scraper.get_search_url_with_limit()
        
        # Chrome kapcsolat
        if not await scraper.connect_to_existing_chrome():
            print("‚ùå Chrome kapcsolat sikertelen")
            return
            
        if not await scraper.get_active_tab():
            print("‚ùå Tab l√©trehoz√°s sikertelen")
            return
        
        print(f"\nüîç Lista scraping ind√≠t√°sa...")
        
        # Ingatlan lista scraping
        properties = await scraper.scrape_property_list(search_url)
        
        if properties:
            # CSV ment√©se
            csv_file = scraper.save_properties_csv(properties, search_url)
            
            print(f"\nüéâ LISTA SCRAPING SIKERES!")
            print(f"üìÅ Kimeneti f√°jl: {csv_file}")
            print(f"üìä √ñsszesen: {len(properties)} ingatlan")
            
            # Opci√≥: r√©szletes scraping ind√≠t√°sa
            print(f"\nüí° K√ñVETKEZ≈ê L√âP√âS:")
            print(f"   A r√©szletes adatok kinyer√©s√©hez haszn√°ld:")
            print(f"   scrape_property_details.py")
            print(f"   √©s v√°laszd ki a {csv_file} f√°jlt")
            
        else:
            print("‚ùå Nem siker√ºlt ingatlanokat tal√°lni")
            
    except KeyboardInterrupt:
        print(f"\n‚è∏Ô∏è Le√°ll√≠tva...")
        
    except Exception as e:
        print(f"‚ùå F≈ëf√ºggv√©ny hiba: {e}")
        
    finally:
        await scraper.close()

if __name__ == "__main__":
    asyncio.run(main())
