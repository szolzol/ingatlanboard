import asyncio
from playwright.async_api import async_playwright
import pandas as pd
import time
import random
from datetime import datetime
import re
from urllib.parse import urlparse, parse_qs, urlencode, urlunparse

class UrlBasedPropertyScraper:
    def __init__(self):
        """URL-alap√∫ ingatlan scraper"""
        self.playwright = None
        self.browser = None
        self.context = None
        self.page = None
        
    async def connect_to_existing_chrome(self):
        """Kapcsol√≥d√°s m√°r fut√≥ Chrome b√∂ng√©sz≈ëh√∂z"""
        try:
            print("üîó Kapcsol√≥d√°s Chrome b√∂ng√©sz≈ëh√∂z...")
            self.playwright = await async_playwright().start()
            self.browser = await self.playwright.chromium.connect_over_cdp("http://localhost:9222")
            print("‚úÖ Chrome kapcsolat l√©trehozva")
            return True
        except Exception as e:
            print(f"‚ùå Chrome kapcsol√≥d√°si hiba: {str(e)}")
            print("üí° Ellen≈ërizd, hogy fut-e a debug Chrome:")
            print("   chrome.exe --remote-debugging-port=9222 --user-data-dir=chrome_debug")
            return False
    
    async def get_active_tab(self):
        """Akt√≠v tab megkeres√©se vagy √∫j tab l√©trehoz√°sa"""
        try:
            contexts = self.browser.contexts
            if not contexts:
                self.context = await self.browser.new_context()
            else:
                self.context = contexts[0]
                
            pages = self.context.pages
            if not pages:
                self.page = await self.context.new_page()
            else:
                self.page = pages[0]
                
            return True
        except Exception as e:
            print(f"‚ùå Tab keres√©si hiba: {str(e)}")
            return False
    
    def get_search_url_with_limit(self):
        """Bek√©ri a felhaszn√°l√≥t√≥l a keres√©si URL-t √©s hozz√°adja a limit param√©tert"""
        print("üîó INGATLAN KERES√âSI URL MEGAD√ÅSA")
        print("="*50)
        print("üí° P√©lda URL-ek:")
        print("   https://ingatlan.com/szukites/elado+lakas+kobanyi-ujhegy")
        print("   https://ingatlan.com/szukites/elado+haz+budapest")
        print("   https://ingatlan.com/szukites/elado+lakas+xiii-kerulet")
        print("")
        
        while True:
            search_url = input("üìç Add meg a keres√©si URL-t: ").strip()
            
            if not search_url:
                print("‚ùå K√©rlek add meg az URL-t!")
                continue
                
            if not search_url.startswith("https://ingatlan.com"):
                print("‚ùå Csak ingatlan.com URL-eket t√°mogatunk!")
                continue
                
            # URL param√©terek kezel√©se
            parsed = urlparse(search_url)
            query_params = parse_qs(parsed.query)
            
            # Limit param√©ter hozz√°ad√°sa/fel√ºl√≠r√°sa
            query_params['limit'] = ['300']
            
            # URL √∫jra√©p√≠t√©se
            new_query = urlencode(query_params, doseq=True)
            enhanced_url = urlunparse((
                parsed.scheme, parsed.netloc, parsed.path,
                parsed.params, new_query, parsed.fragment
            ))
                
            print(f"‚úÖ Tov√°bbfejlesztett URL: {enhanced_url}")
            print(f"üéØ Maximum tal√°latok: 300 ingatlan")
            
            return enhanced_url

    async def human_like_navigation(self, url):
        """Emberszer≈± navig√°l√°s"""
        try:
            await self.page.goto(url, timeout=30000)
            await asyncio.sleep(random.uniform(2.0, 4.0))
            
            # V√©letlenszer≈± scroll
            if random.choice([True, False]):
                scroll_amount = random.randint(200, 800)
                await self.page.evaluate(f"window.scrollBy(0, {scroll_amount})")
                await asyncio.sleep(random.uniform(0.5, 1.5))
                await self.page.evaluate("window.scrollTo(0, 0)")
                
        except Exception as e:
            print(f"  ‚ö†Ô∏è Navig√°l√°si hiba: {e}")

    async def check_for_cloudflare_challenge(self):
        """Cloudflare challenge ellen≈ërz√©se"""
        try:
            cloudflare_indicators = [
                ".cf-browser-verification",
                ".cf-checking-browser", 
                ".cf-challenge-container",
                "#cf-challenge-stage"
            ]
            
            for selector in cloudflare_indicators:
                element = await self.page.query_selector(selector)
                if element and await element.is_visible():
                    return True
                    
            page_title = await self.page.title()
            if page_title and ("checking your browser" in page_title.lower() or 
                              "cloudflare" in page_title.lower()):
                return True
                
            return False
        except:
            return False

    async def scrape_property_list(self, search_url):
        """Ingatlan lista scraping az URL alapj√°n"""
        print(f"\nüè† INGATLAN LISTA SCRAPING")
        print(f"üîó URL: {search_url}")
        
        await self.human_like_navigation(search_url)
        
        # Cloudflare check
        if await self.check_for_cloudflare_challenge():
            print(f"üö® Cloudflare challenge √©szlelve!")
            print(f"üí° Menj a b√∂ng√©sz≈ëbe √©s old meg a challenge-t, majd nyomj ENTER-t")
            input("‚å®Ô∏è  Nyomj ENTER-t a folytat√°shoz...")
            await asyncio.sleep(2)
        
        # Tal√°latok sz√°m√°nak ellen≈ërz√©se
        try:
            result_count_selectors = [
                ".results-num",
                ".search-results-count", 
                "[data-testid='results-count']",
                ".found-results"
            ]
            
            total_results = 0
            for selector in result_count_selectors:
                element = await self.page.query_selector(selector)
                if element:
                    text = await element.inner_text()
                    # Sz√°mok kinyer√©se a sz√∂vegb≈ël
                    numbers = re.findall(r'\d+', text.replace(' ', '').replace('\xa0', ''))
                    if numbers:
                        total_results = int(numbers[-1])  # Utols√≥ sz√°m √°ltal√°ban a tal√°latok sz√°ma
                        break
            
            print(f"üìä Tal√°lt ingatlanok sz√°ma: {total_results}")
            
        except Exception as e:
            print(f"‚ö†Ô∏è Tal√°latok sz√°m√°nak meghat√°roz√°sa sikertelen: {e}")
            total_results = 0
        
        # Ingatlan linkek gy≈±jt√©se
        properties = []
        
        try:
            # Ingatlan k√°rtya selectorok - debug alapj√°n jav√≠tva
            property_card_selectors = [
                ".listing-card",  # Ez m≈±k√∂dik a debug alapj√°n
                ".listing__card", 
                ".result-item",
                ".search-result-item",
                "a[href*='/ingatlan/']"
            ]
            
            property_elements = []
            for selector in property_card_selectors:
                elements = await self.page.query_selector_all(selector)
                if elements:
                    property_elements = elements
                    print(f"‚úÖ Tal√°latok: {len(elements)} elem ({selector})")
                    break
            
            if not property_elements:
                print("‚ùå Nem tal√°lhat√≥k ingatlan elemek")
                return []
            
            print(f"üîç Adatok kinyer√©se {len(property_elements)} ingatlanb√≥l...")
            
            for i, element in enumerate(property_elements, 1):
                try:
                    # Link kinyer√©se
                    link_element = element
                    href = await link_element.get_attribute("href")
                    
                    # Ha nincs href az elemen, keress√ºnk link-et benne
                    if not href:
                        link_element = await element.query_selector("a[href*='/ingatlan/']")
                        if not link_element:
                            continue
                        href = await link_element.get_attribute("href")
                        
                    if not href:
                        continue
                        
                    # Teljes URL l√©trehoz√°sa
                    if href.startswith('/'):
                        full_url = f"https://ingatlan.com{href}"
                    else:
                        full_url = href
                    
                    # Alapadatok kinyer√©se a list√°b√≥l
                    property_data = {
                        'id': i,
                        'link': full_url
                    }
                    
                    # C√≠m kinyer√©se - jav√≠tott megk√∂zel√≠t√©s
                    try:
                        # Keress√ºnk linkeket a listing card-ban
                        link_elements = await element.query_selector_all('a[href*="/ingatlan/"]')
                        for link_elem in link_elements:
                            title_text = await link_elem.inner_text()
                            if title_text and len(title_text.strip()) > 5:  # Legal√°bb 5 karakter
                                property_data['cim'] = title_text.strip()
                                break
                        else:
                            property_data['cim'] = ""
                    except:
                        property_data['cim'] = ""
                    
                    # √År kinyer√©se - jav√≠tott megk√∂zel√≠t√©s  
                    try:
                        # Keress√ºk az √°r sz√∂vegeket tartalmaz√≥ elemeket
                        all_elements = await element.query_selector_all('*')
                        for elem in all_elements:
                            text = await elem.inner_text()
                            if text and ('ft' in text.lower() or 'milli√≥' in text.lower() or re.search(r'\d+\s*M\s*Ft', text)):
                                property_data['teljes_ar'] = text.strip()
                                break
                        else:
                            property_data['teljes_ar'] = ""
                    except:
                        property_data['teljes_ar'] = ""
                    
                    # Ter√ºlet kinyer√©se - jav√≠tott megk√∂zel√≠t√©s
                    try:
                        all_elements = await element.query_selector_all('*')
                        for elem in all_elements:
                            text = await elem.inner_text()
                            if text and ('m¬≤' in text or 'm2' in text) and len(text) < 20:  # R√∂vid sz√∂veg
                                property_data['terulet'] = text.strip()
                                break
                        else:
                            property_data['terulet'] = ""
                    except:
                        property_data['terulet'] = ""
                    
                    # Szob√°k sz√°ma - jav√≠tott megk√∂zel√≠t√©s
                    try:
                        all_elements = await element.query_selector_all('*')
                        for elem in all_elements:
                            text = await elem.inner_text()
                            if text and ('szoba' in text.lower() or '+' in text) and len(text) < 15:
                                property_data['szobak'] = text.strip()
                                break
                        else:
                            property_data['szobak'] = ""
                    except:
                        property_data['szobak'] = ""
                    
                    # N√âGYZETM√âTER √ÅR SZ√ÅM√çT√ÅSA (ha van √°r √©s ter√ºlet)
                    property_data['nm_ar'] = ""
                    if property_data['teljes_ar'] and property_data['terulet']:
                        try:
                            price_num = self._extract_number_from_price(property_data['teljes_ar'])
                            area_num = self._extract_number_from_area(property_data['terulet'])
                            
                            if price_num and area_num:
                                price_per_sqm = int(price_num / area_num)
                                property_data['nm_ar'] = f"{price_per_sqm:,} Ft / m2".replace(',', ' ')
                                
                        except Exception:
                            # Nem kritikus hiba
                            pass
                    
                    properties.append(property_data)
                    
                    if i % 10 == 0:
                        print(f"  üìã Feldolgozva: {i}/{len(property_elements)}")
                        
                except Exception as e:
                    print(f"  ‚ö†Ô∏è {i}. elem feldolgoz√°si hiba: {e}")
                    continue
            
            print(f"‚úÖ Lista scraping befejezve: {len(properties)} ingatlan")
            return properties
            
        except Exception as e:
            print(f"‚ùå Lista scraping hiba: {e}")
            return []

    def save_properties_csv(self, properties, search_url):
        """Ingatlan lista ment√©se CSV-be"""
        if not properties:
            print("‚ùå Nincsenek mentend≈ë adatok")
            return None
            
        try:
            # F√°jln√©v gener√°l√°sa az URL alapj√°n
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            
            # URL-b≈ël keres√©si ter√ºlet kinyer√©se
            url_parts = search_url.split('/')
            search_term = url_parts[-1] if url_parts else "keres√©s"
            search_term = re.sub(r'[^\w\-_]', '_', search_term)[:30]  # Biztons√°gos f√°jln√©v
            
            filename = f"ingatlan_lista_{search_term}_{timestamp}.csv"
            
            df = pd.DataFrame(properties)
            
            # Oszlopok sorrendje
            columns = ['id', 'cim', 'teljes_ar', 'terulet', 'nm_ar', 'szobak', 'link']
            available_columns = [col for col in columns if col in df.columns]
            df = df[available_columns]
            
            df.to_csv(filename, index=False, encoding='utf-8-sig')
            
            print(f"\nüíæ Lista mentve: {filename}")
            print(f"üìä √ñsszesen {len(df)} ingatlan, {len(df.columns)} oszlop")
            
            return filename
            
        except Exception as e:
            print(f"‚ùå CSV ment√©si hiba: {e}")
            return None

    def _extract_number_from_price(self, price_text: str):
        """
        √År sz√∂vegb≈ël numerikus √©rt√©k kinyer√©se.
        
        Args:
            price_text: √År sz√∂veg (pl. "45,5 M Ft", "120 000 Ft")
            
        Returns:
            float or None: Numerikus √°r √©rt√©k
        """
        try:
            # Sz√°mjegyek √©s tizedesjel kinyer√©se
            import re
            numbers = re.findall(r'[\d,\.]+', price_text.replace(' ', ''))
            if numbers:
                num_str = numbers[0].replace(',', '.')
                num_value = float(num_str)
                
                # Milli√≥/milli√°rd szorz√≥ kezel√©se
                if 'M' in price_text.upper():
                    num_value *= 1_000_000
                elif 'MRD' in price_text.upper():
                    num_value *= 1_000_000_000
                
                return num_value
                
        except Exception:
            pass
        
        return None
    
    def _extract_number_from_area(self, area_text: str):
        """
        Ter√ºlet sz√∂vegb≈ël numerikus √©rt√©k kinyer√©se.
        
        Args:
            area_text: Ter√ºlet sz√∂veg (pl. "120 m2")
            
        Returns:
            float or None: Numerikus ter√ºlet √©rt√©k
        """
        try:
            import re
            numbers = re.findall(r'[\d,\.]+', area_text.replace(' ', ''))
            if numbers:
                num_str = numbers[0].replace(',', '.')
                return float(num_str)
                
        except Exception:
            pass
        
        return None

    async def close(self):
        """Kapcsolat bez√°r√°sa"""
        try:
            if self.playwright:
                await self.playwright.stop()
        except:
            pass

async def main():
    """F≈ëf√ºggv√©ny URL-alap√∫ scraping-hez"""
    print("üè† URL-ALAP√ö INGATLAN SCRAPER")
    print("="*60)
    
    scraper = UrlBasedPropertyScraper()
    
    try:
        # URL bek√©r√©se
        search_url = scraper.get_search_url_with_limit()
        
        # Chrome kapcsolat
        if not await scraper.connect_to_existing_chrome():
            print("‚ùå Chrome kapcsolat sikertelen")
            return
            
        if not await scraper.get_active_tab():
            print("‚ùå Tab l√©trehoz√°s sikertelen")
            return
        
        print(f"\nüîç Lista scraping ind√≠t√°sa...")
        
        # Ingatlan lista scraping
        properties = await scraper.scrape_property_list(search_url)
        
        if properties:
            # CSV ment√©se
            csv_file = scraper.save_properties_csv(properties, search_url)
            
            print(f"\nüéâ LISTA SCRAPING SIKERES!")
            print(f"üìÅ Kimeneti f√°jl: {csv_file}")
            print(f"üìä √ñsszesen: {len(properties)} ingatlan")
            
            # Opci√≥: r√©szletes scraping ind√≠t√°sa
            print(f"\nüí° K√ñVETKEZ≈ê L√âP√âS:")
            print(f"   A r√©szletes adatok kinyer√©s√©hez haszn√°ld:")
            print(f"   scrape_property_details.py")
            print(f"   √©s v√°laszd ki a {csv_file} f√°jlt")
            
        else:
            print("‚ùå Nem siker√ºlt ingatlanokat tal√°lni")
            
    except KeyboardInterrupt:
        print(f"\n‚è∏Ô∏è Le√°ll√≠tva...")
        
    except Exception as e:
        print(f"‚ùå F≈ëf√ºggv√©ny hiba: {e}")
        
    finally:
        await scraper.close()

if __name__ == "__main__":
    asyncio.run(main())
