#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Ingatlan le√≠r√°sok sz√∂vegelemz√©se - kulcsszavak √©s √°rbefoly√°sol√≥ t√©nyez≈ëk keres√©se
"""

import pandas as pd
import numpy as np
import re
from collections import Counter, defaultdict
from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer
from sklearn.linear_model import LinearRegression
from sklearn.model_selection import train_test_split
from sklearn.metrics import r2_score, mean_absolute_error
import seaborn as sns
import matplotlib.pyplot as plt

def clean_text(text):
    """Sz√∂veg tiszt√≠t√°sa √©s normaliz√°l√°sa"""
    if pd.isna(text):
        return ""
    text = str(text).lower()
    # HTML tag-ek elt√°vol√≠t√°sa
    text = re.sub(r'<[^>]+>', ' ', text)
    # Speci√°lis karakterek normaliz√°l√°sa
    text = re.sub(r'[^\w\s]', ' ', text)
    # T√∂bbsz√∂r√∂s sz√≥k√∂z√∂k elt√°vol√≠t√°sa
    text = re.sub(r'\s+', ' ', text)
    return text.strip()

def extract_keywords(descriptions, prices, min_freq=3):
    """Kulcsszavak kinyer√©se √©s √°rkorrel√°ci√≥s elemz√©s"""
    
    # Sz√∂vegek tiszt√≠t√°sa
    clean_descriptions = [clean_text(desc) for desc in descriptions]
    
    # Stop words (gyakori, de nem informat√≠v szavak)
    stop_words = {
        'a', 'az', '√©s', 'vagy', 'de', 'hogy', 'van', 'volt', 'lesz', 'is', 'el', 'fel',
        'meg', 'ki', 'be', 'le', '√°t', '√∂ssz', 'sz√©t', 'r√°', 'ide', 'oda', 'minden',
        'egyik', 'm√°sik', 't√∂bb', 'kev√©s', 'sok', 'nagy', 'kicsi', '√∫j', 'r√©gi',
        'j√≥', 'rossz', 'sz√©p', 'cs√∫nya', 'igen', 'nem', 'csak', 'm√°r', 'm√©g', 'itt',
        'ott', 'ahol', 'amikor', 'hogyan', 'mi√©rt', 'mit', 'ki', 'kik', 'hol', 'mikor',
        'ingatlan', 'h√°z', 'lak√°s', 'elad√≥', 'kiad√≥', 'budapest', 'pest', 'megye',
        'utca', '√∫t', 't√©r', 'k√∂r√∫t', 's√©t√°ny', 'k√∂z', 'sor', 'telep', 'ker√ºlet',
        '√©rd', 'erdliget', 'liget', 'di√≥sd', '√©rdliget'
    }
    
    # TF-IDF vektoriz√°ci√≥
    vectorizer = TfidfVectorizer(
        max_features=1000,
        min_df=min_freq,
        max_df=0.8,
        stop_words=list(stop_words),
        ngram_range=(1, 2)  # 1-2 szavas kifejez√©sek
    )
    
    try:
        tfidf_matrix = vectorizer.fit_transform(clean_descriptions)
        feature_names = vectorizer.get_feature_names_out()
        
        # Kulcsszavak √©s √°rak k√∂z√∂tti korrel√°ci√≥
        correlations = []
        
        for i, keyword in enumerate(feature_names):
            keyword_scores = tfidf_matrix[:, i].toarray().flatten()
            
            if len(set(keyword_scores)) > 1:  # Ha van variancia
                correlation = np.corrcoef(keyword_scores, prices)[0, 1]
                if not np.isnan(correlation):
                    correlations.append((keyword, correlation, np.mean(keyword_scores)))
        
        # Korrel√°ci√≥ szerint rendez√©s
        correlations.sort(key=lambda x: abs(x[1]), reverse=True)
        
        return correlations[:50], feature_names, tfidf_matrix
    
    except Exception as e:
        print(f"Hiba a TF-IDF sor√°n: {e}")
        return [], [], None

def analyze_price_keywords(df):
    """√Årbefoly√°sol√≥ kulcsszavak elemz√©se"""
    
    # Csak az √°razott ingatlanokat vizsg√°ljuk
    df_priced = df[df['teljes_ar'].notna() & df['leiras'].notna()].copy()
    
    if len(df_priced) == 0:
        print("‚ùå Nincsenek √°razott ingatlanok le√≠r√°ssal!")
        return None
    
    print(f"üìä Elemzend≈ë ingatlanok: {len(df_priced)} db")
    
    # √År konvert√°l√°sa milli√≥ forintra
    def convert_price(price_str):
        if pd.isna(price_str):
            return np.nan
        price_str = str(price_str).replace(' ', '').replace(',', '.')
        if 'M' in price_str or 'milli√≥' in price_str.lower():
            return float(re.findall(r'[\d.]+', price_str)[0])
        elif 'E' in price_str or 'ezer' in price_str.lower():
            return float(re.findall(r'[\d.]+', price_str)[0]) / 1000
        else:
            # Pr√≥b√°lunk sz√°mot tal√°lni
            numbers = re.findall(r'[\d.]+', price_str)
            if numbers:
                price = float(numbers[0])
                if price > 1000:  # Val√≥sz√≠n≈±leg ezer forintban
                    return price / 1000000
                else:
                    return price
        return np.nan
    
    df_priced['price_mft'] = df_priced['teljes_ar'].apply(convert_price)
    df_priced = df_priced[df_priced['price_mft'].notna()]
    
    print(f"‚úÖ Sikeres √°rkonverzi√≥: {len(df_priced)} db")
    print(f"üí∞ √År tartom√°ny: {df_priced['price_mft'].min():.1f} - {df_priced['price_mft'].max():.1f} M Ft")
    print(f"üìä √Åtlag√°r: {df_priced['price_mft'].mean():.1f} M Ft")
    
    # Kulcsszavak kinyer√©se
    descriptions = df_priced['leiras'].tolist()
    prices = df_priced['price_mft'].tolist()
    
    correlations, feature_names, tfidf_matrix = extract_keywords(descriptions, prices)
    
    if not correlations:
        print("‚ùå Nem tal√°ltunk jelent≈ës kulcsszavakat!")
        return None
    
    # Eredm√©nyek megjelen√≠t√©se
    print(f"\nüîç TOP √ÅRBEFOLY√ÅSOL√ì KULCSSZAVAK:")
    print("=" * 60)
    print(f"{'Kulcssz√≥':<25} {'Korrel√°ci√≥':<12} {'√Åtlag TF-IDF':<12} {'Hat√°s':<10}")
    print("-" * 60)
    
    positive_keywords = []
    negative_keywords = []
    
    for keyword, correlation, avg_score in correlations[:20]:
        effect = "üìà Pozit√≠v" if correlation > 0 else "üìâ Negat√≠v"
        print(f"{keyword:<25} {correlation:>10.3f} {avg_score:>10.4f} {effect}")
        
        if correlation > 0.1:
            positive_keywords.append((keyword, correlation))
        elif correlation < -0.1:
            negative_keywords.append((keyword, correlation))
    
    # Kategoriz√°l√°s
    print(f"\nüèÜ LEGER≈êSEBB POZIT√çV HAT√ÅS√ö KULCSSZAVAK:")
    for keyword, corr in positive_keywords[:10]:
        print(f"  ‚úÖ {keyword}: {corr:.3f}")
    
    print(f"\nüìâ LEGER≈êSEBB NEGAT√çV HAT√ÅS√ö KULCSSZAVAK:")
    for keyword, corr in negative_keywords[:10]:
        print(f"  ‚ùå {keyword}: {corr:.3f}")
    
    return {
        'df_analyzed': df_priced,
        'correlations': correlations,
        'positive_keywords': positive_keywords,
        'negative_keywords': negative_keywords,
        'tfidf_matrix': tfidf_matrix,
        'feature_names': feature_names
    }

def create_text_features(results):
    """Sz√∂vegalap√∫ feature-k l√©trehoz√°sa a modellhez"""
    
    if not results:
        return None
    
    df = results['df_analyzed']
    tfidf_matrix = results['tfidf_matrix']
    feature_names = results['feature_names']
    correlations = results['correlations']
    
    # Top kulcsszavak kiv√°laszt√°sa
    top_keywords = [corr[0] for corr in correlations[:20] if abs(corr[1]) > 0.05]
    
    print(f"\nüîß SZ√ñVEGALAP√ö FEATURE-K L√âTREHOZ√ÅSA:")
    print(f"üìù Kiv√°lasztott kulcsszavak sz√°ma: {len(top_keywords)}")
    
    # Feature m√°trix l√©trehoz√°sa a top kulcsszavakb√≥l
    keyword_indices = [i for i, name in enumerate(feature_names) if name in top_keywords]
    text_features = tfidf_matrix[:, keyword_indices].toarray()
    
    # Feature nevek
    text_feature_names = [f"text_{feature_names[i]}" for i in keyword_indices]
    
    print(f"‚úÖ Feature m√°trix m√©ret: {text_features.shape}")
    
    # Egyszer≈± line√°ris modell a sz√∂vegfeature-kkel
    X = text_features
    y = df['price_mft'].values
    
    if len(X) > 10:  # Ha van el√©g adat
        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)
        
        model = LinearRegression()
        model.fit(X_train, y_train)
        
        y_pred = model.predict(X_test)
        r2 = r2_score(y_test, y_pred)
        mae = mean_absolute_error(y_test, y_pred)
        
        print(f"\nüìä SZ√ñVEGMODELL TELJES√çTM√âNY:")
        print(f"  R¬≤ Score: {r2:.3f}")
        print(f"  MAE: {mae:.1f} M Ft")
        
        # Feature fontoss√°gok
        feature_importance = list(zip(text_feature_names, model.coef_))
        feature_importance.sort(key=lambda x: abs(x[1]), reverse=True)
        
        print(f"\nüéØ TOP FEATURE FONTOSS√ÅGOK:")
        for name, coef in feature_importance[:10]:
            effect = "üìà" if coef > 0 else "üìâ"
            print(f"  {effect} {name.replace('text_', '')}: {coef:+.2f} M Ft")
        
        results['text_model'] = {
            'model': model,
            'feature_names': text_feature_names,
            'r2_score': r2,
            'mae': mae,
            'feature_importance': feature_importance
        }
    
    return results

def main():
    """F≈ë elemz√©si folyamat"""
    print("üè† INGATLAN LE√çR√ÅSOK SZ√ñVEGELEMZ√âSE")
    print("=" * 50)
    
    # Adatok bet√∂lt√©se
    try:
        df = pd.read_csv('ingatlan_reszletes_elado_haz_erd_erdliget_20250820_014506.csv')
        print(f"üìä Bet√∂lt√∂tt rekordok: {len(df)}")
        print(f"üìù Le√≠r√°ssal rendelkez≈ëk: {df['leiras'].notna().sum()}")
        
        # Elemz√©s futtat√°sa
        results = analyze_price_keywords(df)
        
        if results:
            # Sz√∂vegalap√∫ feature-k l√©trehoz√°sa
            results = create_text_features(results)
            
            print(f"\n‚úÖ ELEMZ√âS BEFEJEZVE!")
            print(f"üíæ Eredm√©nyek elmentve a results objektumba")
            
            return results
        else:
            print("‚ùå Az elemz√©s nem siker√ºlt!")
            return None
            
    except Exception as e:
        print(f"‚ùå Hiba t√∂rt√©nt: {e}")
        return None

if __name__ == "__main__":
    results = main()
