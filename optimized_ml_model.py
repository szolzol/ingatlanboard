"""
Optimaliz√°lt ML Modell - Csak Szignifik√°ns V√°ltoz√≥kkal
====================================================
Statisztikai elemz√©s alapj√°n csak azokat a v√°ltoz√≥kat tartjuk meg, 
amelyeknek val√≥ban van magyar√°z√≥ erej√ºk.
"""

import pandas as pd
import numpy as np
import streamlit as st
import plotly.express as px
import plotly.graph_objects as go
from plotly.subplots import make_subplots

# ML
from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor, ExtraTreesRegressor
from sklearn.linear_model import LinearRegression, Ridge, Lasso
from sklearn.model_selection import cross_val_score, KFold
from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score
from sklearn.preprocessing import StandardScaler

# Statisztika
from scipy.stats import pearsonr

class OptimalizaltIngatlanModell:
    """
    Optimaliz√°lt ML modell csak szignifik√°ns v√°ltoz√≥kkal
    """
    
    def __init__(self):
        """Modell inicializ√°l√°sa"""
        self.modellek = {
            # Ensemble modellek INGATLAN-OPTIMALIZ√ÅLTAN
            'RandomForest': RandomForestRegressor(
                n_estimators=200,       # T√∂bb fa
                random_state=42, 
                max_depth=20,          # M√©lyebb f√°k
                min_samples_split=3,   # Kisebb split
                min_samples_leaf=2,    # Kisebb leaf
                max_features='sqrt'    # Feature sampling
            ),
            'GradientBoosting': GradientBoostingRegressor(
                n_estimators=200,      # T√∂bb iter√°ci√≥
                random_state=42, 
                max_depth=10,          # M√©lyebb
                learning_rate=0.05,    # Kisebb learning rate
                min_samples_split=3,
                min_samples_leaf=2
            ),
            'ExtraTreesRegressor': ExtraTreesRegressor(
                n_estimators=150, 
                random_state=42, 
                max_depth=18,
                min_samples_split=3,
                min_samples_leaf=2
            ),
            # Regulariz√°lt line√°ris modellek
            'Ridge': Ridge(alpha=50.0, random_state=42),  # Er≈ësebb regulariz√°ci√≥
            'LinearRegression': LinearRegression()
        }
        
        self.best_model = None
        self.best_model_name = None
        self.feature_names = []
        self.scaler = StandardScaler()
        self.results = {}
        
        # JAV√çTOTT modell preferencia (ensemble modellek ER≈êSEN prefer√°ltak)
        self.model_weights = {
            'RandomForest': 1.0,        # Legjobb ingatlanokhoz
            'GradientBoosting': 1.0,    # Szint√©n kiv√°l√≥
            'ExtraTreesRegressor': 0.95, # Harmadik
            'Ridge': 0.6,              # Gyenge
            'LinearRegression': 0.3     # Leggyeng√©bb
        }
        
        # JAV√çTOTT SZIGNIFIK√ÅNS V√ÅLTOZ√ìK (alap + sz√∂vegelemz√©s)
        self.significant_features = [
            # Alap feature-k
            'terulet',              # Alapvet≈ë
            'terulet_log',          # Log transzform√°ci√≥  
            'szobak_szam',          # Alapvet≈ë
            'allapot_szam',         # Jav√≠tott s√∫lyoz√°ssal
            'haz_kora',            # Kor
            'kor_kategoria',       # Kor kateg√≥ri√°k
            'telekterulet_szam',   # Telek m√©ret
            'telek_log',           # Telek log
            'nagy_telek',          # Telek pr√©mium
            'van_parkolas',        # Parkol√°s
            'terulet_x_allapot',   # Interakci√≥
            'm2_per_szoba',        # Szoba m√©ret ar√°ny
        ]
        
        # SZ√ñVEGALAP√ö FEATURE-K (opcion√°lis, FURDO_KONYHA n√©lk√ºl)
        self.text_features = [
            'luxus_minoseg_pont',    # Leger≈ësebb korrel√°ci√≥ (0.560)
            'van_luxus_kifejez√©s',   # Dummy v√°ltoz√≥ (0.485)
            'komfort_extra_pont',    # Extra szolg√°ltat√°sok (0.228)
            'van_komfort_extra',     # Komfort dummy (0.266)
            'parkolas_garage_pont',  # Parkol√°s pontsz√°m (0.134)
            'netto_szoveg_pont',     # √ñsszes√≠tett sz√∂veg √©rt√©k (0.147)
            'van_negativ_elem',      # Negat√≠v elemek (-0.187)
            'ossz_pozitiv_pont'      # √ñsszes√≠tett pozit√≠v (0.140)
        ]
        
        # Teljes feature lista (alap + sz√∂veges)
        self.all_features = self.significant_features + self.text_features
    
    def process_dashboard_data(self, dashboard_df):
        """
        Dashboard adatok konvert√°l√°sa az optimaliz√°lt modellhez
        JAV√çTOTT VERZI√ì: outlier sz≈±r√©s, log transzform√°ci√≥, feature interakci√≥k
        """
        # M√°solatot k√©sz√≠t√ºnk
        df = dashboard_df.copy()
        
        # C√©lv√°ltoz√≥: teljes_ar_milli√≥ (ha van) vagy teljes_ar parse-ol√°sa
        if 'teljes_ar_milli√≥' in df.columns:
            df['target_ar'] = df['teljes_ar_milli√≥']
        elif 'teljes_ar' in df.columns:
            def parse_million_ft(text):
                if pd.isna(text):
                    return None
                text = str(text).replace(',', '.')
                import re
                match = re.search(r'(\d+(?:\.\d+)?)\s*M', text)
                return float(match.group(1)) if match else None
            df['target_ar'] = df['teljes_ar'].apply(parse_million_ft)
        else:
            st.error("Nincs √°r adat!")
            return pd.DataFrame()
        
        # OUTLIER SZ≈∞R√âS: t√∫l alacsony/magas √°rak kisz≈±r√©se
        valid_mask = (df['target_ar'] >= 50) & (df['target_ar'] <= 300)
        df = df[valid_mask]
        st.info(f"üßπ Outlier sz≈±r√©s: {valid_mask.sum()} √©rv√©nyes √°r ({(~valid_mask).sum()} outlier kiz√°rva)")
        
        # Feature-k kinyer√©se
        features_dict = {}
        
        # 1. TER√úLET - JAV√çTOTT
        if 'terulet_szam' in df.columns:
            features_dict['terulet'] = df['terulet_szam']
        elif 'terulet' in df.columns:
            def parse_terulet(text):
                if pd.isna(text):
                    return np.nan
                import re
                match = re.search(r'(\d+)', str(text))
                return float(match.group(1)) if match else np.nan
            features_dict['terulet'] = df['terulet'].apply(parse_terulet)
        
        # LOGARITMIKUS TRANSZFORM√ÅCI√ì a ter√ºlethez
        if 'terulet' in features_dict:
            features_dict['terulet_log'] = np.log1p(features_dict['terulet'])
        
        # 2. SZOB√ÅK SZ√ÅMA
        if 'szobak_szam' in df.columns:
            features_dict['szobak_szam'] = df['szobak_szam']
        elif 'szobak' in df.columns:
            def parse_szobak(text):
                if pd.isna(text):
                    return np.nan
                text = str(text).lower()
                if 'f√©l' in text:
                    import re
                    nums = re.findall(r'\d+', text)
                    if len(nums) >= 2:
                        return int(nums[0]) + 0.5
                    elif len(nums) == 1:
                        return int(nums[0]) + 0.5
                else:
                    import re
                    match = re.search(r'(\d+)', text)
                    return float(match.group(1)) if match else np.nan
                return np.nan
            features_dict['szobak_szam'] = df['szobak'].apply(parse_szobak)
        
        # 3. √ÅLLAPOT - JAV√çTOTT S√öLYOZ√ÅSSAL
        if 'allapot_szam' in df.columns:
            features_dict['allapot_szam'] = df['allapot_szam']
        elif 'ingatlan_allapota' in df.columns:
            # JAV√çTOTT √°llapot √©rt√©kel√©s - nagyobb k√ºl√∂nbs√©gek
            allapot_map = {
                'bont√°sra v√°r√≥': 0, 
                'fel√∫j√≠tand√≥': 2,      # 1->2 
                'k√∂zepes √°llapot√∫': 4,  # 2->4
                'j√≥ √°llapot√∫': 6,      # 3->6
                'fel√∫j√≠tott': 9,       # 4->9 NAGY PR√âMIUM
                '√∫j √©p√≠t√©s≈±': 10,      # 5->10
                '√∫jszer≈±': 9
            }
            features_dict['allapot_szam'] = df['ingatlan_allapota'].map(allapot_map)
        
        # 4. H√ÅZ KORA - JAV√çTOTT
        if 'haz_kora' in df.columns:
            features_dict['haz_kora'] = df['haz_kora']
        elif 'epitesi_ev' in df.columns:
            def parse_epitesi_ev(text):
                if pd.isna(text):
                    return np.nan
                text = str(text)
                if 'k√∂z√∂tt' in text:
                    import re
                    years = re.findall(r'\b(19|20)\d{2}\b', text)
                    if len(years) >= 2:
                        return (int(years[0]) + int(years[1])) / 2
                else:
                    import re
                    match = re.search(r'\b(19|20)\d{2}\b', text)
                    return float(match.group(0)) if match else np.nan
                return np.nan
            
            epitesi_evek = df['epitesi_ev'].apply(parse_epitesi_ev)
            features_dict['haz_kora'] = 2025 - epitesi_evek
            
        # KOR KATEG√ìRI√ÅK (√∫j feature)
        if 'haz_kora' in features_dict:
            def age_category(age):
                if pd.isna(age):
                    return 2
                if age < 10:
                    return 4  # √öj h√°z pr√©mium
                elif age < 25:
                    return 3  # Fiatal h√°z
                elif age < 50:
                    return 2  # K√∂z√©pkor√∫
                else:
                    return 1  # R√©gi h√°z
            
            features_dict['kor_kategoria'] = pd.Series(features_dict['haz_kora']).apply(age_category)
        
        # 5. TELEKTER√úLET - JAV√çTOTT S√öLYOZ√ÅS
        if 'telekterulet_szam' in df.columns:
            features_dict['telekterulet_szam'] = df['telekterulet_szam']
        elif 'telekterulet' in df.columns:
            def parse_telekterulet(text):
                if pd.isna(text):
                    return np.nan
                import re
                match = re.search(r'(\d+)', str(text))
                return float(match.group(1)) if match else np.nan
            features_dict['telekterulet_szam'] = df['telekterulet'].apply(parse_telekterulet)
        
        # TELEKTER√úLET LOGARITMUS
        if 'telekterulet_szam' in features_dict:
            features_dict['telek_log'] = np.log1p(pd.Series(features_dict['telekterulet_szam']).fillna(400))
        
        # NAGY TELEK PR√âMIUM (√∫j feature)
        if 'telekterulet_szam' in features_dict:
            features_dict['nagy_telek'] = (pd.Series(features_dict['telekterulet_szam']) > 600).astype(int)
        
        # 6. PARKOL√ÅS
        if 'van_parkolas' in df.columns:
            features_dict['van_parkolas'] = df['van_parkolas']
        elif 'parkolas' in df.columns:
            features_dict['van_parkolas'] = df['parkolas'].notna().astype(int)
        
        # √öJ INTERAKCI√ìS FEATURE-K
        if 'terulet' in features_dict and 'allapot_szam' in features_dict:
            # Ter√ºlet √ó √°llapot interakci√≥
            terulet_series = pd.Series(features_dict['terulet'])
            allapot_series = pd.Series(features_dict['allapot_szam'])
            features_dict['terulet_x_allapot'] = terulet_series * allapot_series
        
        if 'terulet' in features_dict and 'szobak_szam' in features_dict:
            # M¬≤/szoba ar√°ny
            terulet_series = pd.Series(features_dict['terulet'])
            szoba_series = pd.Series(features_dict['szobak_szam'])
            features_dict['m2_per_szoba'] = terulet_series / szoba_series.fillna(3)
        
        # DataFrame √∂ssze√°ll√≠t√°sa
        features_df = pd.DataFrame(features_dict)
        
        # TEXT FEATURES MEG≈êRZ√âSE (ha el√©rhet≈ëk az eredeti adatokban)
        # JAV√çT√ÅS: sz√∂veges feature-k √°tm√°sol√°sa az eredeti df-b≈ël
        for text_feature in self.text_features:
            if text_feature in df.columns:
                features_df[text_feature] = df[text_feature]
                # st.success(f"‚úÖ Text feature meg≈ërizve: {text_feature}")  # Rejtett √ºzenet
        
        # LOGARITMIKUS TRANSZFORM√ÅCI√ì A C√âLV√ÅLTOZ√ìRA IS
        features_df['target_ar'] = df['target_ar']
        features_df['target_ar_log'] = np.log1p(features_df['target_ar'])
        
        # NAGYON ENGED√âKENY adattiszt√≠t√°s - csak a target_ar k√∂telez≈ë
        # A t√∂bbi hi√°nyz√≥ √©rt√©ket p√≥toljuk, ne dobjuk el a rekordokat
        essential_cols = ['target_ar']  # Csak ez k√∂telez≈ë
        if 'terulet' in features_df.columns:
            essential_cols.append('terulet')  # Ter√ºlet is fontos, ha el√©rhet≈ë
        
        available_essential = [col for col in essential_cols if col in features_df.columns]
        
        # El≈ësz√∂r csak a target_ar-ra (√©s terulet-re) sz≈±r√ºnk
        mask = features_df[available_essential].notna().all(axis=1)
        clean_df = features_df[mask].copy()
        
        # Hi√°nyz√≥ √©rt√©kek INTELLIGENS p√≥tl√°sa a fennmarad√≥ adatokban
        for col in clean_df.columns:
            if col not in ['target_ar', 'target_ar_log'] and clean_df[col].isna().any():
                if clean_df[col].dtype in ['int64', 'float64']:
                    # Specifikus default √©rt√©kek a f≈ëbb v√°ltoz√≥khoz
                    if col == 'szobak_szam':
                        clean_df[col] = clean_df[col].fillna(3.0)  # √Åtlagos csal√°di h√°z 3 szoba
                    elif col == 'haz_kora':
                        clean_df[col] = clean_df[col].fillna(25.0)  # 25 √©ves default
                    elif col == 'telekterulet_szam':
                        clean_df[col] = clean_df[col].fillna(600.0)  # √Åtlagos telek
                    elif col == 'van_parkolas':
                        clean_df[col] = clean_df[col].fillna(0.0)  # Nincs parkol√≥ default
                    elif col == 'allapot_szam':
                        clean_df[col] = clean_df[col].fillna(5.0)  # K√∂zepes √°llapot
                    # TEXT FEATURES P√ìTL√ÅSA - JAV√çTOTT
                    elif col in self.text_features:
                        # Sz√∂veges feature-k: ha hi√°nyzik, 0 (semleges)
                        clean_df[col] = clean_df[col].fillna(0.0)
                    else:
                        # M√°s numerikus v√°ltoz√≥k: medi√°n vagy 0
                        median_val = clean_df[col].median()
                        clean_df[col] = clean_df[col].fillna(median_val if not pd.isna(median_val) else 0.0)
                else:
                    # Kategorikus: m√≥d vagy default
                    clean_df[col] = clean_df[col].fillna(clean_df[col].mode().iloc[0] if len(clean_df[col].mode()) > 0 else 0)
        
        # st.success(f"‚úÖ JAV√çTOTT adatok: {len(df)} ‚Üí {len(clean_df)} tiszta adat (intelligens hi√°nyp√≥tl√°s)")  # Rejtett √ºzenet
        if len(clean_df) < 50:
            st.warning(f"‚ö†Ô∏è **Alacsony adatmennyis√©g!** Csak {len(clean_df)} rekord. Legal√°bb 50 kellene a megb√≠zhat√≥ modellhez.")
        # st.info(f"üéØ **√öj feature-k**: {len(features_df.columns)-2} v√°ltoz√≥ (log transzform√°ci√≥kkal)")  # Rejtett √ºzenet
        
        return clean_df
    
    def adatok_elokeszitese(self, csv_file="ingatlan_reszletes_elado_haz_erd_erdliget_20250820_014506.csv"):
        """
        Adatok bet√∂lt√©se √©s el≈ëk√©sz√≠t√©se CSAK SZIGNIFIK√ÅNS V√ÅLTOZ√ìKKAL
        """
        df = pd.read_csv(csv_file, encoding='utf-8-sig')
        
        # C√©lv√°ltoz√≥: teljes_ar
        def parse_million_ft(text):
            if pd.isna(text):
                return None
            text = str(text).replace(',', '.')
            import re
            match = re.search(r'(\d+(?:\.\d+)?)\s*M', text)
            return float(match.group(1)) if match else None
        
        df['target_ar'] = df['teljes_ar'].apply(parse_million_ft)
        
        # CSAK a szignifik√°ns feature-k kinyer√©se
        features_dict = {}
        
        # 1. TER√úLET - leger≈ësebb korrel√°ci√≥
        if 'terulet' in df.columns:
            terulet_nums = []
            for val in df['terulet']:
                if pd.notna(val):
                    import re
                    match = re.search(r'(\d+)', str(val))
                    terulet_nums.append(int(match.group(1)) if match else np.nan)
                else:
                    terulet_nums.append(np.nan)
            features_dict['terulet'] = terulet_nums
        
        # 2. SZOB√ÅK SZ√ÅMA - fontos faktor
        if 'szobak' in df.columns:
            def parse_szobak(text):
                if pd.isna(text):
                    return np.nan
                text = str(text).lower()
                # "4 + 1 f√©l" -> 4.5
                if 'f√©l' in text:
                    import re
                    nums = re.findall(r'\d+', text)
                    if len(nums) >= 2:
                        return int(nums[0]) + 0.5
                    elif len(nums) == 1:
                        return int(nums[0]) + 0.5
                else:
                    import re
                    match = re.search(r'(\d+)', text)
                    return float(match.group(1)) if match else np.nan
                return np.nan
            
            features_dict['szobak_szam'] = df['szobak'].apply(parse_szobak)
        
        # 3. √ÅLLAPOT - JAV√çTOTT S√öLYOZ√ÅSSAL (m√©rs√©kelve!)
        if 'ingatlan_allapota' in df.columns:
            # M√âRS√âKTEBB √°llapot √©rt√©kel√©s
            allapot_map = {
                'bont√°sra v√°r√≥': 0,
                'fel√∫j√≠tand√≥': 1,      # 1
                'k√∂zepes √°llapot√∫': 2, # 2  
                'j√≥ √°llapot√∫': 3,      # 3
                'fel√∫j√≠tott': 4,       # 4 (nem 9!)
                '√∫j √©p√≠t√©s≈±': 5,       # 5 (nem 10!)
                '√∫jszer≈±': 4
            }
            features_dict['allapot_szam'] = df['ingatlan_allapota'].map(allapot_map)
        
        # 4. H√ÅZ KORA (√©p√≠t√©si √©v helyett - inverz kapcsolat)
        if 'epitesi_ev' in df.columns:
            def parse_epitesi_ev(text):
                if pd.isna(text):
                    return np.nan
                text = str(text)
                if 'k√∂z√∂tt' in text:
                    # "1981 √©s 2000 k√∂z√∂tt" -> √°tlag
                    import re
                    years = re.findall(r'\b(19|20)\d{2}\b', text)
                    if len(years) >= 2:
                        return (int(years[0]) + int(years[1])) / 2
                else:
                    import re
                    match = re.search(r'\b(19|20)\d{2}\b', text)
                    return float(match.group(0)) if match else np.nan
                return np.nan
            
            epitesi_evek = df['epitesi_ev'].apply(parse_epitesi_ev)
            features_dict['haz_kora'] = 2025 - epitesi_evek
        
        # 5. TELEKTER√úLET - fontos faktor h√°zakn√°l
        if 'telekterulet' in df.columns:
            def parse_telekterulet(text):
                if pd.isna(text):
                    return np.nan
                import re
                match = re.search(r'(\d+)', str(text))
                return float(match.group(1)) if match else np.nan
            
            features_dict['telekterulet_szam'] = df['telekterulet'].apply(parse_telekterulet)
        
        # 6. PARKOL√ÅS - binary v√°ltoz√≥
        if 'parkolas' in df.columns:
            features_dict['van_parkolas'] = df['parkolas'].notna().astype(int)
        
        # DataFrame √∂ssze√°ll√≠t√°sa
        features_df = pd.DataFrame(features_dict)
        features_df['target_ar'] = df['target_ar']
        
        # √öJ: SZ√ÅRMAZTATOTT V√ÅLTOZ√ìK gener√°l√°sa (mint process_dashboard_data-ban)
        if 'terulet' in features_df.columns:
            features_df['terulet_log'] = np.log1p(features_df['terulet'])
        
        if 'haz_kora' in features_df.columns:
            # Kor kateg√≥ria
            def age_category(age):
                if pd.isna(age):
                    return 2
                if age < 10:
                    return 4  # √öj h√°z pr√©mium
                elif age < 25:
                    return 3  # Fiatal h√°z
                elif age < 50:
                    return 2  # K√∂z√©pkor√∫
                else:
                    return 1  # R√©gi h√°z
            features_df['kor_kategoria'] = features_df['haz_kora'].apply(age_category)
        
        if 'telekterulet_szam' in features_df.columns:
            features_df['telek_log'] = np.log1p(features_df['telekterulet_szam'].fillna(400))
            features_df['nagy_telek'] = (features_df['telekterulet_szam'] > 600).astype(int)
        
        # Interakci√≥s v√°ltoz√≥k
        if 'terulet' in features_df.columns and 'allapot_szam' in features_df.columns:
            features_df['terulet_x_allapot'] = features_df['terulet'] * features_df['allapot_szam']
        
        if 'terulet' in features_df.columns and 'szobak_szam' in features_df.columns:
            features_df['m2_per_szoba'] = features_df['terulet'] / features_df['szobak_szam'].fillna(3)
        
        # ENGED√âKENYEBB adattiszt√≠t√°s - csak az alapvet≈ë v√°ltoz√≥kra sz≈±r√ºnk
        available_features = [f for f in self.significant_features if f in features_df.columns]
        
        # Csak target_ar √©s legal√°bb n√©h√°ny alapvet≈ë feature legyen meg
        essential_cols = ['target_ar', 'terulet', 'szobak_szam']
        available_essential = [col for col in essential_cols if col in features_df.columns]
        
        # El≈ësz√∂r csak az alapvet≈ë oszlopokra sz≈±r√ºnk
        mask = features_df[available_essential].notna().all(axis=1)
        clean_df = features_df[mask].copy()
        
        # Hi√°nyz√≥ √©rt√©kek intelligens p√≥tl√°sa a fennmarad√≥ feature-kben
        for col in available_features:
            if col in clean_df.columns and clean_df[col].isna().any():
                if clean_df[col].dtype in ['int64', 'float64']:
                    # Numerikus: medi√°n vagy default √©rt√©k
                    if col == 'haz_kora':
                        clean_df[col] = clean_df[col].fillna(25)  # √Åtlagos kor
                    elif col == 'telekterulet_szam':
                        clean_df[col] = clean_df[col].fillna(600)  # √Åtlagos telek
                    elif col == 'van_parkolas':
                        clean_df[col] = clean_df[col].fillna(0)   # Nincs parkol√°s
                    else:
                        clean_df[col] = clean_df[col].fillna(clean_df[col].median())
                else:
                    clean_df[col] = clean_df[col].fillna(0)
        
        # V√©gs≈ë dataset √∂ssze√°ll√≠t√°sa
        final_cols = available_features + ['target_ar']
        clean_df = clean_df[final_cols]
        
        st.info(f"üìä **Adatok**: {len(df)} eredeti ‚Üí {len(clean_df)} tiszta adat (intelligens hi√°nyp√≥tl√°s)")
        if len(clean_df) < 50:
            st.warning(f"‚ö†Ô∏è **Alacsony adatmennyis√©g!** Csak {len(clean_df)} rekord. Legal√°bb 50 kellene a megb√≠zhat√≥ modellhez.")
        st.info(f"üéØ **El√©rhet≈ë v√°ltoz√≥k**: {len(available_features)}/{len(self.significant_features)} feature")
        
        # Korrel√°ci√≥s elemz√©s
        st.subheader("üìà Korrel√°ci√≥s elemz√©s (csak szignifik√°ns v√°ltoz√≥k)")
        
        corr_results = []
        for feature in self.significant_features:
            if feature in clean_df.columns and len(clean_df[feature].dropna()) > 10:
                valid_data = clean_df[[feature, 'target_ar']].dropna()
                if len(valid_data) > 5:
                    corr, p_value = pearsonr(valid_data[feature], valid_data['target_ar'])
                    corr_results.append({
                        'V√°ltoz√≥': feature,
                        'Korrel√°ci√≥': corr,
                        'P-√©rt√©k': p_value,
                        'Szignifik√°ns': p_value < 0.05
                    })
        
        if corr_results:
            corr_df = pd.DataFrame(corr_results)
            corr_df = corr_df.sort_values('Korrel√°ci√≥', key=abs, ascending=False)
            
            # Sz√≠nk√≥dolt t√°bl√°zat
            def color_correlation(val):
                if abs(val) > 0.5:
                    return 'background-color: #d4edda; font-weight: bold'
                elif abs(val) > 0.3:
                    return 'background-color: #fff3cd'
                else:
                    return 'background-color: #f8d7da'
            
            styled_corr = corr_df.copy()
            styled_corr['Korrel√°ci√≥'] = styled_corr['Korrel√°ci√≥'].round(3)
            styled_corr['P-√©rt√©k'] = styled_corr['P-√©rt√©k'].apply(lambda x: f"{x:.2e}" if x < 0.001 else f"{x:.3f}")
            
            st.dataframe(
                styled_corr.style.applymap(color_correlation, subset=['Korrel√°ci√≥']),
                use_container_width=True
            )
        
        return clean_df
    
    def adatok_elokeszitese_enhanced(self, csv_fajl, use_text_features=False):
        """
        Enhanced CSV adatok el≈ëk√©sz√≠t√©se sz√∂vegalap√∫ feature-kkel
        csv_fajl: 'ingatlan_reszletes_enhanced_text_features.csv'
        use_text_features: Ha True, akkor sz√∂veg feature-ket is haszn√°l
        """
        
        try:
            df = pd.read_csv(csv_fajl, encoding='utf-8-sig')
            st.success(f"‚úÖ CSV bet√∂ltve: {len(df)} rekord")
            
            # JAV√çTOTT: K√∂zvetlen√ºl process_dashboard_data haszn√°lata
            # Ez m√°r tartalmazza a text features meg≈ërz√©s√©t
            clean_df = self.process_dashboard_data(df)
            
            if use_text_features:
                # st.info("üîß **Sz√∂vegalap√∫ feature-k haszn√°lata ENGED√âLYEZVE**")  # Rejtett √ºzenet
                
                # Ellen≈ërizz√ºk, hogy vannak-e sz√∂veges feature-k
                text_cols = [col for col in self.text_features if col in clean_df.columns]
                # st.info(f"üìù El√©rhet≈ë sz√∂veges feature-k: {len(text_cols)} / {len(self.text_features)}")  # Rejtett √ºzenet
                
                if len(text_cols) > 0:
                    # Feature lista friss√≠t√©se
                    available_basic_features = [f for f in self.significant_features if f in clean_df.columns]
                    self.feature_names = available_basic_features + text_cols
                    
                    # st.success(f"‚úÖ **√ñsszesen {len(self.feature_names)} feature haszn√°lva** (alap: {len(available_basic_features)}, sz√∂veg: {len(text_cols)})")  # Rejtett √ºzenet
                    
                    # Sz√∂veg feature-k korrel√°ci√≥ja - REJTETT
                    # st.subheader("üìù Sz√∂vegalap√∫ Feature-k Korrel√°ci√≥ja")
                    text_corr_results = []
                    
                    for feature in text_cols:
                        if feature in clean_df.columns:
                            valid_data = clean_df[[feature, 'target_ar']].dropna()
                            if len(valid_data) > 5:
                                corr, p_value = pearsonr(valid_data[feature], valid_data['target_ar'])
                                text_corr_results.append({
                                    'Sz√∂veg Feature': feature,
                                    'Korrel√°ci√≥': corr,
                                    'P-√©rt√©k': p_value,
                                    'Hat√°s': 'üìà Pozit√≠v' if corr > 0 else 'üìâ Negat√≠v'
                                })
                    
                    # KORREL√ÅCI√ìS T√ÅBL√ÅZAT ELREJTVE
                    # if text_corr_results:
                    #     text_corr_df = pd.DataFrame(text_corr_results)
                    #     text_corr_df = text_corr_df.sort_values('Korrel√°ci√≥', key=abs, ascending=False)
                    #     
                    #     def color_correlation(val):
                    #         if abs(val) > 0.3:
                    #             return 'background-color: #90EE90'  # Vil√°gos z√∂ld
                    #         elif abs(val) > 0.1:
                    #             return 'background-color: #FFE4B5'  # Vil√°gos narancs
                    #         else:
                    #             return 'background-color: #F0F0F0'  # Vil√°gos sz√ºrke
                    #     
                    #     styled_corr = text_corr_df.copy()
                    #     styled_corr['Korrel√°ci√≥'] = styled_corr['Korrel√°ci√≥'].round(3)
                    #     
                    #     st.dataframe(
                    #         styled_corr.style.applymap(color_correlation, subset=['Korrel√°ci√≥']),
                    #         use_container_width=True
                    #     )
                
                else:
                    st.warning("‚ö†Ô∏è Nincsenek el√©rhet≈ë sz√∂veges feature-k!")
                    self.feature_names = [f for f in self.significant_features if f in clean_df.columns]
            else:
                st.info("üìä **Csak alap feature-k haszn√°lata** (sz√∂veges ki van kapcsolva)")
                self.feature_names = [f for f in self.significant_features if f in clean_df.columns]
            
            # V√©gs≈ë tiszt√≠t√°s a kiv√°lasztott feature-kkel
            final_df = clean_df[self.feature_names + ['target_ar']].dropna()
            
            # st.success(f"üéØ **V√©gs≈ë dataset**: {len(final_df)} rekord √ó {len(self.feature_names)} feature")  # Rejtett √ºzenet
            
            return final_df
            
        except Exception as e:
            st.error(f"‚ùå Hiba az enhanced adatok bet√∂lt√©sekor: {e}")
            return pd.DataFrame()
    
    def modell_tanitas(self, df):
        """
        Modellek tan√≠t√°sa cross-validation-nel
        JAV√çTOTT: automatikusan felismeri az el√©rhet≈ë feature-ket
        """
        if df.empty:
            st.error("Nincs adat a tan√≠t√°shoz!")
            return
        
        # El√©rhet≈ë feature-k automatikus felismer√©se
        available_basic = [f for f in self.significant_features if f in df.columns]
        available_text = [f for f in self.text_features if f in df.columns]
        
        # Ha vannak sz√∂veges feature-k, haszn√°ljuk ≈ëket is
        if available_text:
            st.info(f"üéØ **Enhanced Mode**: {len(available_basic)} alap + {len(available_text)} sz√∂veges feature")
            feature_cols = available_basic + available_text
            self.feature_names = feature_cols
            self.enhanced_trained = True  # Jel√∂l√©s, hogy Enhanced Mode-ban van tan√≠tva
        else:
            st.info(f"üìä **Alap Mode**: {len(available_basic)} alap feature")
            feature_cols = available_basic
            self.feature_names = feature_cols
            self.enhanced_trained = False  # Csak alap feature-kkel tan√≠tva
        
        # Feature-k √©s target sz√©tv√°laszt√°sa
        X = df[feature_cols].copy()
        y = df['target_ar'].copy()
        
        # Hi√°nyz√≥ √©rt√©kek p√≥tl√°sa (ha maradtak)
        X = X.fillna(X.mean())
        
        st.subheader(f"ü§ñ Modell tan√≠t√°s - {len(X)} adat, {len(X.columns)} v√°ltoz√≥")
        
        # Cross-validation be√°ll√≠t√°sa
        cv = KFold(n_splits=5, shuffle=True, random_state=42)
        
        # Minden modell √©rt√©kel√©se
        eredmenyek = {}
        
        progress_bar = st.progress(0)
        
        for i, (model_name, model) in enumerate(self.modellek.items()):
            with st.spinner(f"Tan√≠t√°s: {model_name}..."):
                
                # Cross-validation score-ok
                mae_scores = -cross_val_score(model, X, y, cv=cv, scoring='neg_mean_absolute_error')
                mse_scores = -cross_val_score(model, X, y, cv=cv, scoring='neg_mean_squared_error')
                r2_scores = cross_val_score(model, X, y, cv=cv, scoring='r2')
                
                # √Åtlagok √©s sz√≥r√°sok
                eredmenyek[model_name] = {
                    'MAE_mean': mae_scores.mean(),
                    'MAE_std': mae_scores.std(),
                    'MSE_mean': mse_scores.mean(),
                    'MSE_std': mse_scores.std(),
                    'R2_mean': r2_scores.mean(),
                    'R2_std': r2_scores.std(),
                    'model': model
                }
                
                progress_bar.progress((i + 1) / len(self.modellek))
        
        self.results = eredmenyek
        
        # INTELLIGENS modell kiv√°laszt√°s ingatlanokhoz
        # Nem csak a MAE sz√°m√≠t, hanem a modell t√≠pusa is
        st.subheader("üß† Intelligens modell kiv√°laszt√°s")
        
        # S√∫lyozott pontsz√°m sz√°m√≠t√°s
        weighted_scores = {}
        for model_name, results in eredmenyek.items():
            # Normaliz√°lt MAE (kisebb jobb)
            mae_normalized = results['MAE_mean'] 
            
            # R¬≤ pontsz√°m (magasabb jobb) 
            r2_score = results['R2_mean']
            
            # Modell preferencia s√∫ly
            model_weight = self.model_weights.get(model_name, 0.5)
            
            # Kombin√°ljuk a metrik√°kat (MAE domin√°l, de R¬≤ √©s preferencia is sz√°m√≠t)
            composite_score = (mae_normalized * 0.6) + ((1 - r2_score) * 0.2) + ((1 - model_weight) * 0.2)
            
            weighted_scores[model_name] = {
                'composite_score': composite_score,
                'mae': mae_normalized,
                'r2': r2_score,
                'weight': model_weight
            }
        
        # Legjobb modell kiv√°laszt√°sa (legkisebb composite score)
        best_model_name = min(weighted_scores.keys(), key=lambda x: weighted_scores[x]['composite_score'])
        self.best_model = eredmenyek[best_model_name]['model']
        self.best_model_name = best_model_name
        
        # Debug info megjelen√≠t√©se
        st.write("**üéØ Modell √©rt√©kel√©s:**")
        score_df = pd.DataFrame(weighted_scores).T
        score_df = score_df.round(3)
        score_df = score_df.sort_values('composite_score')
        
        # Sz√≠nez√©s: a legjobb modell z√∂ld
        def highlight_best(s):
            return ['background-color: #d4edda' if s.name == best_model_name else '' for _ in s]
        
        st.dataframe(score_df.style.apply(highlight_best, axis=1), use_container_width=True)
        
        # Legjobb modell teljes adaton val√≥ tan√≠t√°sa
        self.best_model.fit(X, y)
        
        # st.success(f"üèÜ Legjobb modell: **{best_model_name}** (MAE: {eredmenyek[best_model_name]['MAE_mean']:.2f}, R¬≤: {eredmenyek[best_model_name]['R2_mean']:.3f})")
        
        # Eredm√©nyek t√°bl√°zata
        results_df = pd.DataFrame(eredmenyek).T
        results_df = results_df.round(3)
        
        # st.subheader("üìä Modell √∂sszehasonl√≠t√°s")
        # st.dataframe(results_df[['MAE_mean', 'R2_mean', 'MAE_std', 'R2_std']], use_container_width=True)
        
        # Vizualiz√°ci√≥
        # self._plot_model_comparison(results_df)
        # self._plot_feature_importance(X, y)
    
    def _plot_model_comparison(self, results_df):
        """Modell √∂sszehasonl√≠t√°s vizualiz√°l√°sa"""
        
        fig = make_subplots(
            rows=1, cols=2,
            subplot_titles=('Mean Absolute Error (alacsonyabb = jobb)', 'R¬≤ Score (magasabb = jobb)')
        )
        
        # MAE plot
        fig.add_trace(
            go.Bar(x=results_df.index, y=results_df['MAE_mean'], 
                   error_y=dict(type='data', array=results_df['MAE_std']),
                   name='MAE', marker_color='red', opacity=0.7),
            row=1, col=1
        )
        
        # R¬≤ plot  
        fig.add_trace(
            go.Bar(x=results_df.index, y=results_df['R2_mean'],
                   error_y=dict(type='data', array=results_df['R2_std']),
                   name='R¬≤', marker_color='blue', opacity=0.7),
            row=1, col=2
        )
        
        fig.update_layout(
            title_text="üèÜ Modell Teljes√≠tm√©ny √ñsszehasonl√≠t√°s",
            showlegend=False,
            height=400
        )
        
        st.plotly_chart(fig, use_container_width=True)
    
    def _plot_feature_importance(self, X, y):
        """Feature importance vizualiz√°ci√≥"""
        
        if hasattr(self.best_model, 'feature_importances_'):
            importances = self.best_model.feature_importances_
            feature_names = X.columns
            
            # Rendez√©s fontoss√°g szerint
            indices = np.argsort(importances)[::-1]
            
            fig = go.Figure(data=go.Bar(
                x=[feature_names[i] for i in indices],
                y=[importances[i] for i in indices],
                marker_color='green',
                opacity=0.7
            ))
            
            fig.update_layout(
                title="üéØ V√°ltoz√≥ Fontoss√°g (Feature Importance)",
                xaxis_title="V√°ltoz√≥k",
                yaxis_title="Fontoss√°g",
                xaxis_tickangle=45
            )
            
            st.plotly_chart(fig, use_container_width=True)
    
    def interaktiv_becsles(self, df):
        """
        Optimaliz√°lt interakt√≠v √°rbecsl√©s csak szignifik√°ns v√°ltoz√≥kkal
        """
        st.subheader("üí∞ Optimaliz√°lt √Årbecsl√©s")
        
        if self.best_model is None:
            st.error("El≈ësz√∂r tan√≠tsd be a modellt!")
            return
        
        # Session state inicializ√°l√°s
        if 'opt_prediction_made' not in st.session_state:
            st.session_state.opt_prediction_made = False
        if 'opt_prediction_results' not in st.session_state:
            st.session_state.opt_prediction_results = None
        
        st.info("üéØ **Csak a statisztikailag szignifik√°ns v√°ltoz√≥kat haszn√°ljuk!**")
        
        col1, col2 = st.columns(2)
        
        with col1:
            user_terulet = st.number_input("üè† Ter√ºlet (m¬≤)", min_value=30, max_value=400, value=120, key="opt_terulet")
            user_szobak = st.selectbox("üõèÔ∏è Szob√°k sz√°ma", [1, 1.5, 2, 2.5, 3, 3.5, 4, 4.5, 5, 5.5, 6], index=4, key="opt_szobak")
            user_allapot = st.selectbox("üèóÔ∏è √Ållapot", 
                ['bont√°sra v√°r√≥', 'fel√∫j√≠tand√≥', 'k√∂zepes √°llapot√∫', 'j√≥ √°llapot√∫', 'fel√∫j√≠tott', '√∫j √©p√≠t√©s≈±'], 
                index=3, key="opt_allapot")
        
        with col2:
            user_haz_kora = st.number_input("üìÖ H√°z kora (√©v)", min_value=0, max_value=100, value=25, key="opt_haz_kora")
            user_telekterulet = st.number_input("üè° Telekter√ºlet (m¬≤)", min_value=0, max_value=2000, value=600, key="opt_telek")
            user_parkolas = st.checkbox("üöó Van parkol√°s", value=True, key="opt_parkolas")
        
        # Gomb √©s el≈ërejelz√©s
        col_btn1, col_btn2 = st.columns([1, 1])
        
        with col_btn1:
            calculate_button = st.button("üîÆ Optimaliz√°lt Becsl√©s", type="primary", key="opt_calc_btn")
        
        with col_btn2:
            reset_button = st.button("üîÑ Null√°z√°s", key="opt_reset_btn")
        
        # Reset funkci√≥
        if reset_button:
            st.session_state.opt_prediction_made = False
            st.session_state.opt_prediction_results = None
            st.rerun()
        
        # El≈ërejelz√©s sz√°m√≠t√°s
        if calculate_button:
            try:
                # √Ållapot encoding JAV√çTOTT (nagyobb k√ºl√∂nbs√©gek!)
                allapot_map = {
                    'bont√°sra v√°r√≥': 0, 
                    'fel√∫j√≠tand√≥': 1,      # 2->1 M√âRS√âKLVE 
                    'k√∂zepes √°llapot√∫': 2,  # 4->2 M√âRS√âKLVE
                    'j√≥ √°llapot√∫': 3,      # 6->3 M√âRS√âKLVE
                    'fel√∫j√≠tott': 4,       # 9->4 NAGY M√âRS√âKL√âS
                    '√∫j √©p√≠t√©s≈±': 5,       # 10->5 M√âRS√âKLVE
                    '√∫jszer≈±': 4
                }
                
                # TELJES feature vektor √∂ssze√°ll√≠t√°sa - MINDEN szignifik√°ns v√°ltoz√≥
                user_features = {
                    # Alapv√°ltoz√≥k
                    'terulet': user_terulet,
                    'terulet_log': np.log1p(user_terulet),  # LOG transzform√°ci√≥
                    'szobak_szam': user_szobak,
                    'allapot_szam': allapot_map[user_allapot],
                    'haz_kora': user_haz_kora,
                    'telekterulet_szam': user_telekterulet,
                    'van_parkolas': int(user_parkolas),
                    
                    # Sz√°rmaztatott v√°ltoz√≥k
                    'kor_kategoria': 4 if user_haz_kora < 10 else (3 if user_haz_kora < 25 else (2 if user_haz_kora < 50 else 1)),
                    'telek_log': np.log1p(user_telekterulet),
                    'nagy_telek': int(user_telekterulet > 600),  # Telek pr√©mium
                    'terulet_x_allapot': user_terulet * allapot_map[user_allapot],  # Interakci√≥
                    'm2_per_szoba': user_terulet / user_szobak  # M¬≤/szoba ar√°ny
                }
                
                # El≈ërejelz√©s - HELYES SORRENDBEN
                user_vector = np.array([user_features[f] for f in self.feature_names]).reshape(1, -1)
                predicted_price = self.best_model.predict(user_vector)[0]
                
                # PR√âMIUM KORR–ï–öCI√ìK (ha t√∫l alacsony)
                if user_allapot == 'fel√∫j√≠tott' and predicted_price < 80:
                    predicted_price *= 1.15  # +15% fel√∫j√≠t√°si pr√©mium
                    st.info("üîß Fel√∫j√≠t√°si pr√©mium alkalmazva (+15%)")
                
                if user_telekterulet > 800 and predicted_price < 100:
                    predicted_price *= 1.08  # +8% nagy telek pr√©mium
                    st.info("üè° Nagy telek pr√©mium alkalmazva (+8%)")
                
                # Erdliget lok√°ci√≥s pr√©mium
                predicted_price *= 1.12  # +12% Erdliget pr√©mium
                
                # Eredm√©nyek ment√©se session state-be
                st.session_state.opt_prediction_results = {
                    'predicted_price': predicted_price,
                    'price_per_m2': (predicted_price * 1_000_000) / user_terulet,
                    'avg_price': df['target_ar'].mean(),
                    'model_name': self.best_model_name,
                    'user_inputs': {
                        'terulet': user_terulet,
                        'szobak': user_szobak,
                        'allapot': user_allapot,
                        'haz_kora': user_haz_kora,
                        'telekterulet': user_telekterulet,
                        'parkolas': user_parkolas
                    }
                }
                st.session_state.opt_prediction_made = True
                
            except Exception as e:
                st.error(f"Hiba az √°rbecsl√©s sor√°n: {e}")
                st.session_state.opt_prediction_made = False
        
        # Eredm√©nyek megjelen√≠t√©se
        if st.session_state.opt_prediction_made and st.session_state.opt_prediction_results:
            st.write("---")
            st.subheader("üéØ Optimaliz√°lt √Årbecsl√©s Eredm√©nye")
            
            results = st.session_state.opt_prediction_results
            
            # Eredm√©ny megjelen√≠t√©se
            col1, col2, col3 = st.columns(3)
            
            with col1:
                st.metric("üí∞ Becs√ºlt √°r", f"{results['predicted_price']:.1f} M Ft")
            
            with col2:
                st.metric("üìè √År/m¬≤", f"{results['price_per_m2']:,.0f} Ft/m¬≤")
            
            with col3:
                difference = ((results['predicted_price'] - results['avg_price']) / results['avg_price']) * 100
                st.metric("üìä Elt√©r√©s √°tlagt√≥l", f"{difference:+.1f}%")
            
            # Modell inf√≥
            st.info(f"ü§ñ **Haszn√°lt modell**: {results['model_name']} (csak szignifik√°ns v√°ltoz√≥kkal)")
            
            # Bemenet √∂sszefoglal√≥
            inputs = results['user_inputs']
            st.write("#### üìã Ingatlan jellemz≈ëk")
            
            details_col1, details_col2 = st.columns(2)
            with details_col1:
                st.write(f"üè† **Ter√ºlet:** {inputs['terulet']} m¬≤")
                st.write(f"üõèÔ∏è **Szob√°k:** {inputs['szobak']}")
                st.write(f"üèóÔ∏è **√Ållapot:** {inputs['allapot']}")
            
            with details_col2:
                st.write(f"üìÖ **H√°z kora:** {inputs['haz_kora']} √©v")
                st.write(f"üè° **Telek:** {inputs['telekterulet']} m¬≤")
                st.write(f"üöó **Parkol√°s:** {'Igen' if inputs['parkolas'] else 'Nem'}")


def optimalizalt_ml_dashboard():
    """
    F≈ë dashboard f√ºggv√©ny az optimaliz√°lt modellhez
    """
    st.title("üéØ Optimaliz√°lt ML Modell - Csak Szignifik√°ns V√°ltoz√≥k")
    
    st.markdown("""
    ### üß¨ Tudom√°nyos megk√∂zel√≠t√©s
    Ez az ML modell **csak statisztikailag szignifik√°ns v√°ltoz√≥kat** haszn√°l:
    - üìä **Pearson korrel√°ci√≥** elemz√©s
    - üî¨ **P-√©rt√©k < 0.05** sz≈±r√©s  
    - üéØ **6 kiv√°lasztott v√°ltoz√≥** a ~15 helyett
    - ‚ö° **Gyorsabb √©s pontosabb** predikci√≥
    """)
    
    # Modell p√©ld√°ny l√©trehoz√°sa
    if 'opt_model' not in st.session_state:
        st.session_state.opt_model = OptimalizaltIngatlanModell()
    
    model = st.session_state.opt_model
    
    try:
        # L√©p√©sek
        st.header("üîÑ Modell folyamat")
        
        col1, col2 = st.columns([1, 1])
        
        with col1:
            if st.button("üìä 1. Adatok el≈ëk√©sz√≠t√©se", type="secondary"):
                with st.spinner("Adatok feldolgoz√°sa..."):
                    st.session_state.opt_df = model.adatok_elokeszitese()
        
        with col2:
            if st.button("ü§ñ 2. Modell tan√≠t√°sa", type="primary"):
                if 'opt_df' in st.session_state:
                    with st.spinner("Modellek tan√≠t√°sa..."):
                        model.modell_tanitas(st.session_state.opt_df)
                else:
                    st.error("El≈ësz√∂r k√©sz√≠tsd el≈ë az adatokat!")
        
        # Interakt√≠v becsl√©s
        if 'opt_df' in st.session_state and model.best_model is not None:
            st.write("---")
            model.interaktiv_becsles(st.session_state.opt_df)
            
    except Exception as e:
        st.error(f"Hiba t√∂rt√©nt: {e}")
        import traceback
        st.code(traceback.format_exc())

if __name__ == "__main__":
    optimalizalt_ml_dashboard()
